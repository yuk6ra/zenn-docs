---
title: "ã€GR00T N1 Ã— LeRobotã€‘ç‹¬è‡ªã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã‚’å®Ÿè·µã™ã‚‹æ–¹æ³•"
emoji: "ğŸ¤–"
type: "tech"
topics: ["AI", "NVIDIA", "GR00T", "LeRobot", "ãƒ­ãƒœãƒƒãƒˆåŸºç›¤ãƒ¢ãƒ‡ãƒ«"]
published: true
---

# ã¯ã˜ã‚ã«

NVIDIAãŒç™ºè¡¨ã—ãŸäººå‹ãƒ­ãƒœãƒƒãƒˆã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã€ŒProject GR00Tã€ã¯ã€AIã¨ãƒ­ãƒœãƒƒãƒˆã®ä¸–ç•Œã«å¤§ããªå¤‰é©ã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ã‚’ç§˜ã‚ã¦ã„ã¾ã™ã€‚ã“ã®GR00T N1ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã ã‘ã§ãªãå®Ÿä¸–ç•Œã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ãŸå‹•ä½œç”ŸæˆãŒå¯èƒ½ã§ã™ã€‚

æœ¬è¨˜äº‹ã§ã¯ã€ã‚·ãƒ³ã‚°ãƒ«ã‚¢ãƒ¼ãƒ ã€ŒSO-ARM101ã€ã§åé›†ã—ãŸç‹¬è‡ªã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã„ã€GR00T N1ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‹ã‚‰ã€å®Ÿæ©Ÿã§ã®æ¨è«–ã€ãã—ã¦å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¾ã§ã®ä¸€é€£ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã€å…·ä½“çš„ãªæ‰‹é †ã¨è©³ç´°ãªãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’äº¤ãˆãªãŒã‚‰ç¶²ç¾…çš„ã«è§£èª¬ã—ã¾ã™ã€‚

ã“ã®è¨˜äº‹ã‚’èª­ã‚ã°ã€ç‹¬è‡ªã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãƒ­ãƒœãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ç¬¬ä¸€æ­©ã‚’è¸ã¿å‡ºã›ã‚‹ã¯ãšã§ã™ã€‚

## æœ¬è¨˜äº‹ã§è§£èª¬ã™ã‚‹å†…å®¹

1.  **ãƒ‡ãƒ¼ã‚¿é¸å®šç·¨**ï¼šå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¦‚è¦ã¨ã€ãƒ‡ãƒ¼ã‚¿åé›†æ™‚ã®è¨­å®šã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚
2.  **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç·¨**ï¼šGR00T N1ãƒ¢ãƒ‡ãƒ«ã‚’ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚
3.  **æ¨è«–ç·¨**ï¼šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ã€å®Ÿæ©Ÿãƒ­ãƒœãƒƒãƒˆã‚’åˆ¶å¾¡ã—ã¾ã™ã€‚
4.  **è©•ä¾¡ç·¨**ï¼šå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å®šé‡çš„ã«è©•ä¾¡ã—ã¾ã™ã€‚

## å‚è€ƒè³‡æ–™

æœ¬è¨˜äº‹ã¯ã€ä»¥ä¸‹ã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚„ãƒ–ãƒ­ã‚°ã‚’å‚è€ƒã«ã€ç‰¹å®šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å‹•ä½œç¢ºèªã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚

-   **å…¬å¼ãƒ–ãƒ­ã‚°**: [Fine-tuning GR00T N1 with LeRobot on a custom dataset](https://huggingface.co/blog/nvidia/gr00t-n1-5-so101-tuning)
-   **GitHub**: [NVIDIA/Isaac-GR00T](https://github.com/NVIDIA/Isaac-GR00T) / [huggingface/lerobot](https://github.com/huggingface/lerobot)
    - **Isaac-GR00T**: [`d598400`](https://github.com/NVIDIA/Isaac-GR00T/tree/d5984002e24d418872adc5822a5bbb1d6a9b4ddc)(ä»Šå›ä½¿ç”¨)
    -   **LeRobot**: [`519b761`](https://github.com/huggingface/lerobot/tree/519b76110efeea55a4f919895d0029dc0df41e8b)(ä»Šå›ä½¿ç”¨)


**NOTE**: ãƒªãƒã‚¸ãƒˆãƒªã®æ›´æ–°ãŒé€Ÿã„ãŸã‚ã€åŒæ§˜ã®ç’°å¢ƒã‚’å†ç¾ã™ã‚‹éš›ã¯ã”æ³¨æ„ãã ã•ã„ã€‚

# ãƒ‡ãƒ¼ã‚¿é¸å®šç·¨

ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯ã€è³ªã®é«˜ã„å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒä¸å¯æ¬ ã§ã™ã€‚æœ¬è¨˜äº‹ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿åé›†ãƒ—ãƒ­ã‚»ã‚¹ã¯å®Œäº†ã—ã¦ã„ã‚‹å‰æã§é€²ã‚ã¾ã™ãŒã€ã©ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã„ã€ã©ã®ã‚ˆã†ã«åé›†ã—ãŸã‹ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ã‚¿ã‚¹ã‚¯ã®é¸å®š

ä»Šå›ã¯ã€ä»¥ä¸‹ã®3ã¤ã®ã‚¿ã‚¹ã‚¯ã®ä¸­ã‹ã‚‰æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªã€Œãƒ†ãƒ¼ãƒ—ã‚’1ã¤æ´ã‚“ã§ç®±ã«å…¥ã‚Œã‚‹ã€ã‚¿ã‚¹ã‚¯ã‚’é¸æŠã—ã¾ã—ãŸã€‚è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã¯æˆåŠŸç‡ãŒä¸‹ãŒã‚Šã‚„ã™ã„ãŸã‚ã€ã¾ãšã¯ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã‹ã‚‰å§‹ã‚ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯[LeRobot Dataset Visualizer](https://huggingface.co/spaces/lerobot/visualize_dataset)ã§å¯è¦–åŒ–ã§ãã¾ã™ã€‚

-   **è¤‡é›‘ãªã‚¿ã‚¹ã‚¯**: [`pen-cleanup`](https://huggingface.co/spaces/lerobot/visualize_dataset?path=%2Fyuk6ra%2Fso101-pen-cleanup%2Fepisode_0)
-   **ç°¡å˜ãªã‚¿ã‚¹ã‚¯**: [`tapes-cleanup`](https://huggingface.co/spaces/lerobot/visualize_dataset?path=%2Fyuk6ra%2Fso101-tapes-cleanup%2Fepisode_0)
-   **æœ€ã‚‚ç°¡å˜ãªã‚¿ã‚¹ã‚¯**: [`onetape-cleanup`](https://huggingface.co/spaces/lerobot/visualize_dataset?path=%2Fyuk6ra%2Fso101-onetape-cleanup%2Fepisode_0) (ä»Šå›ä½¿ç”¨)

## ãƒ‡ãƒ¼ã‚¿åé›†æ™‚ã®è¨­å®š

ä»¥ä¸‹ã«ã€ä»Šå›ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ50ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰ã®åé›†è¨­å®šã‚’ç¤ºã—ã¾ã™ã€‚

ç‰¹ã«é‡è¦ãªã®ãŒ`cameras`ã®è¨­å®šã§ã™ã€‚ã“ã“ã§å®šç¾©ã—ãŸã‚«ãƒ¡ãƒ©åï¼ˆä¾‹: `tip`, `front`ï¼‰ã¯ã€å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å·¥ç¨‹ã§å‚ç…§ã•ã‚Œã‚‹ãŸã‚ã€æ­£ç¢ºã«è¦šãˆã¦ãŠãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚**GR00Tã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã«åˆã‚ã›ã¦`wrist`ã¨ã„ã†åå‰ã‚’ä½¿ã†ã¨ã€å¾Œã®è¨­å®šå¤‰æ›´ã®æ‰‹é–“ãŒçœã‘ã‚‹ãŸã‚æ¨å¥¨ã—ã¾ã™ã€‚**

```yaml:config.yaml
dataset:
  repo_id: "yuk6ra/so101-onetape-cleanup"  # Hugging Face ã®ãƒªãƒã‚¸ãƒˆãƒªID
  single_task: "Grab the tape and place it in the box."  # ã‚¿ã‚¹ã‚¯ã®èª¬æ˜
  num_episodes: 50  # è¨˜éŒ²ã™ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°
  fps: 30  # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ
  episode_time_s: 15  # 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§æ™‚é–“ï¼ˆç§’ï¼‰
  reset_time_s: 15  # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜éŒ²å¾Œã®ãƒªã‚»ãƒƒãƒˆæ™‚é–“ï¼ˆç§’ï¼‰

# ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã‚¢ãƒ¼ãƒ 
robot:
  type: "so101_follower"
  port: "/dev/ttyACM0"  # ã‚·ãƒªã‚¢ãƒ«ãƒãƒ¼ãƒˆ
  id: "white"  # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã®ID
  
  # ã‚«ãƒ¡ãƒ©è¨­å®š (ã“ã“ã§å®šç¾©ã—ãŸåå‰ã‚’å¾Œã§ä½¿ã„ã¾ã™)
  cameras:
    tip: # 'wrist' ã«ã—ã¦ãŠãã¨å¾Œå·¥ç¨‹ãŒã‚¹ãƒ ãƒ¼ã‚º
      type: "opencv"
      index_or_path: 0
      fps: 30
      width: 640
      height: 480
    front:
      type: "opencv"
      index_or_path: 2
      fps: 30
      width: 640
      height: 480

# ãƒªãƒ¼ãƒ€ãƒ¼ã‚¢ãƒ¼ãƒ 
teleop:
  type: "so101_leader" 
  port: "/dev/ttyACM1"  # ã‚·ãƒªã‚¢ãƒ«ãƒãƒ¼ãƒˆ
  id: "black"  # ãƒªãƒ¼ãƒ€ãƒ¼ã®ID

# è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³
options:
  display_data: false  # ã‚«ãƒ¡ãƒ©æ˜ åƒã‚’è¡¨ç¤ºã™ã‚‹ã‹
  push_to_hub: true # Hugging Face Hub ã«è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹
```

# ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç·¨

åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€GR00T N1ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚

## å®Ÿè¡Œç’°å¢ƒã®æº–å‚™

ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯é«˜ã„ã‚¹ãƒšãƒƒã‚¯ã®ãƒã‚·ãƒ³ãŒå¿…è¦ã§ã™ã€‚ä»Šå›ã¯ä»¥ä¸‹ã®ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§å®Ÿè¡Œã—ã¾ã—ãŸã€‚

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | ã‚¹ãƒšãƒƒã‚¯                               |
| :--------------- | :------------------------------------- |
| **GPU**          | NVIDIA H100 SXM (VRAM 80GB)                |
| **Disk**         | 300GBä»¥ä¸Š (5000ã‚¹ãƒ†ãƒƒãƒ—ã§ç´„100GBæ¶ˆè²») |
| **RAM**          | 128GBä»¥ä¸Š                              |
| **OS**           | Ubuntu 24.04                           |
| **ãƒãƒƒãƒˆé€Ÿåº¦**   | 4Gbps (ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰)      |

**NOTE**: ãƒãƒƒãƒˆé€Ÿåº¦ãŒé…ã„ã¨ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«ã‹ãªã‚Šã®æ™‚é–“ã‚’è¦ã—ã¾ã™ã€‚

SSHã§ãƒªãƒ¢ãƒ¼ãƒˆã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šå¾Œã€å„ç¨®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¹ãƒšãƒƒã‚¯ã‚’ç¢ºèªã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚

```shell:SSHæ¥ç¶š
ssh -p 30454 root@xxx.xxx.xxx.xx -L 8080:localhost:8080
```

```shell:GPUã®ç¢ºèª
# GPUã®ç¢ºèª
$ nvidia-smi
Sun Jul 13 06:57:05 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:E4:00.0 Off |                    0 |
| N/A   47C    P0             73W /  700W |       1MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

```shell:Diskã®ç¢ºèª
$ df /home -h
Filesystem      Size  Used Avail Use% Mounted on
overlay         300G   90M  300G   1% /
```

```shell:RAMã®ç¢ºèª
$ free -h
               total        used        free      shared  buff/cache   available
Mem:           503Gi        34Gi       372Gi        47Mi       101Gi       469Gi
Swap:          8.0Gi       186Mi       7.8Gi
```

```shell:OSã®ç¢ºèª
$ lsb_release -d
No LSB modules are available.
Description:    Ubuntu 24.04.2 LTS
```

æ¬¡ã«ã€å…¬å¼ã®æŒ‡ç¤ºã«å¾“ã„ã€Condaã§ä»®æƒ³ç’°å¢ƒã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

```shell
# ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/NVIDIA/Isaac-GR00T
cd Isaac-GR00T

# Condaç’°å¢ƒã‚’ä½œæˆã—ã¦æœ‰åŠ¹åŒ–
conda create -n gr00t python=3.10
conda activate gr00t

# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install --upgrade setuptools
pip install -e .[base]
pip install --no-build-isolation flash-attn==2.7.1.post4
```

æœ€å¾Œã«ã€Hugging Faceã¨Weights & Biases (Wandb) ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚

-   **Hugging Face Token**: [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
-   **Wandb API Key**: [wandb.ai/authorize](https://wandb.ai/authorize)

```shell
huggingface-cli login
wandb login
```

## å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™

Hugging Face Hubã‹ã‚‰ä»»æ„ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

```shell
huggingface-cli download \
       --repo-type dataset yuk6ra/so101-onetape-cleanup \
       --local-dir ./demo_data/so101-onetape-cleanup
```

GR00TãŒãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’æ­£ã—ãèªè­˜ã§ãã‚‹ã‚ˆã†ã«ã€`modality.json`ã¨ã„ã†è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã—ã€å†…å®¹ã‚’è‡ªåˆ†ã®ç’°å¢ƒã«åˆã‚ã›ã¦ä¿®æ­£ã—ã¾ã™ã€‚

```shell
# ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
cp getting_started/examples/so100_dualcam__modality.json ./demo_data/so101-onetape-cleanup/meta/modality.json
```

ãƒ‡ãƒ¼ã‚¿åé›†æ™‚ã«è¨­å®šã—ãŸã‚«ãƒ¡ãƒ©åï¼ˆ`tip`ï¼‰ã«åˆã‚ã›ã¦ã€`wrist`ã®è¨˜è¿°ã‚’`tip`ã«å¤‰æ›´ã—ã¾ã™ã€‚

```shell
# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†
vim ./demo_data/so101-onetape-cleanup/meta/modality.json
```

```diff:modality.json
 {
    ...
        "video": {
            "front": {
                "original_key": "observation.images.front"
            },
-           "wrist": {
-               "original_key": "observation.images.wrist"
+           "tip": { 
+               "original_key": "observation.images.tip" 
            }
        },
    ...
```

ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãèª­ã¿è¾¼ã‚ã‚‹ã‹ã€ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ç¢ºèªã—ã¾ã™ã€‚

```sh
python scripts/load_dataset.py \
    --dataset-path ./demo_data/so101-onetape-cleanup \
    --plot-state-action \
    --video-backend torchvision_av
```

æˆåŠŸã™ã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹é€ æƒ…å ±ã‚„ãƒ•ãƒ¬ãƒ¼ãƒ æƒ…å ±ãŒå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚

```shell:å®Ÿè¡Œçµæœ
====================================================================================================
========================================= Humanoid Dataset =========================================
====================================================================================================
{'action.gripper': 'np scalar: 1.1111111640930176 [1, 1] float64',
 'action.single_arm': 'np: [1, 5] float64',
 'annotation.human.task_description': ['Grab the tape and place it in the '
                                       'box.'],
 'state.gripper': 'np scalar: 2.410423517227173 [1, 1] float64',
 'state.single_arm': 'np: [1, 5] float64',
 'video.front': 'np: [1, 480, 640, 3] uint8',
 'video.tip': 'np: [1, 480, 640, 3] uint8'}
dict_keys(['video.front', 'video.tip', 'state.single_arm', 'state.gripper', 'action.single_arm', 'action.gripper', 'annotation.human.task_description'])
==================================================
video.front: (1, 480, 640, 3)
video.tip: (1, 480, 640, 3)
state.single_arm: (1, 5)
state.gripper: (1, 1)
action.single_arm: (1, 5)
action.gripper: (1, 1)
annotation.human.task_description: ['Grab the tape and place it in the box.']
Image 0, prompt: ['Grab the tape and place it in the box.']
Image 10, prompt: ['Grab the tape and place it in the box.']
Image 20, prompt: ['Grab the tape and place it in the box.']
Image 30, prompt: ['Grab the tape and place it in the box.']
Image 40, prompt: ['Grab the tape and place it in the box.']
Image 50, prompt: ['Grab the tape and place it in the box.']
Image 60, prompt: ['Grab the tape and place it in the box.']
Image 70, prompt: ['Grab the tape and place it in the box.']
Image 80, prompt: ['Grab the tape and place it in the box.']
Image 90, prompt: ['Grab the tape and place it in the box.']
Image 100, prompt: ['Grab the tape and place it in the box.']
Image 110, prompt: ['Grab the tape and place it in the box.']
Image 120, prompt: ['Grab the tape and place it in the box.']
Image 130, prompt: ['Grab the tape and place it in the box.']
Image 140, prompt: ['Grab the tape and place it in the box.']
Image 150, prompt: ['Grab the tape and place it in the box.']
Image 160, prompt: ['Grab the tape and place it in the box.']
Image 170, prompt: ['Grab the tape and place it in the box.']
Image 180, prompt: ['Grab the tape and place it in the box.']
Image 190, prompt: ['Grab the tape and place it in the box.']
Warning: Skipping left_arm as it's not found in both state and action dictionaries
Warning: Skipping right_arm as it's not found in both state and action dictionaries
Warning: Skipping left_hand as it's not found in both state and action dictionaries
Warning: Skipping right_hand as it's not found in both state and action dictionaries
Plotted state and action space
```

## å­¦ç¿’ã®å®Ÿè¡Œ

æº–å‚™ãŒæ•´ã£ãŸã‚‰ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™ã€‚H100 GPUã§ç´„30åˆ†ã‹ã‹ã‚Šã€5000ã‚¹ãƒ†ãƒƒãƒ—ã®å­¦ç¿’ã§ç´„100GBã®ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’æ¶ˆè²»ã—ã¾ã—ãŸã€‚

```sh
python scripts/gr00t_finetune.py \
      --dataset-path ./demo_data/so101-onetape-cleanup/ \
      --num-gpus 1 \
      --output-dir ./so101-checkpoints  \
      --max-steps 5000 \
      --data-config so100_dualcam \
      --video-backend torchvision_av
```

ã‚‚ã—ãƒ¡ãƒ¢ãƒªãªã©ã‚¹ãƒšãƒƒã‚¯ãŒè¶³ã‚Šãªã„å ´åˆã¯ã€`--dataloader-num-workers`ã‚„`--batch-size`ã‚’å°ã•ãã—ã¦è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```shell: ã‚¹ãƒšãƒƒã‚¯ãŒè¶³ã‚Šãªã‹ã£ãŸå ´åˆ
python scripts/gr00t_finetune.py \
     --dataset-path ./demo_data/so101-onetape-cleanup/ \
     --num-gpus 1 \
     --output-dir ./so101-checkpoints  \
     --max-steps 5000 \
     --data-config so100_dualcam \
     --batch-size 8 \
     --video-backend torchvision_av \
     --dataloader-num-workers 0
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚¨ãƒ©ãƒ¼1: `ValueError: Video key wrist not found`

ã“ã®ã‚¨ãƒ©ãƒ¼ã¯ã€å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚«ãƒ¡ãƒ©å`wrist`ã‚’æ¢ã—ã«è¡Œãã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®`tip`ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œãªã„ãŸã‚ã«ç™ºç”Ÿã—ã¾ã™ã€‚

**è§£æ±ºç­–:** `gr00t/experiment/data_config.py`ã‚’ç›´æ¥ç·¨é›†ã—ã€ã‚«ãƒ¡ãƒ©åã‚’ä¿®æ­£ã—ã¾ã™ã€‚

```diff:gr00t/experiment/data_config.py
# 225è¡Œç›®ã‚ãŸã‚Š
class So100DualCamDataConfig(So100DataConfig):
-   video_keys = ["video.front", "video.wrist"]
+   video_keys = ["video.front", "video.tip"]
```

### ã‚¨ãƒ©ãƒ¼2: `av.error.MemoryError: [Errno 12] Cannot allocate memory`

ãƒ“ãƒ‡ã‚ªãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ä¸­ã«ãƒ¡ãƒ¢ãƒªä¸è¶³ãŒç™ºç”Ÿã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼ã§ã™ã€‚

```shell:ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
  0%|                                                                                                                            | 0/5000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/workspace/Isaac-GR00T/scripts/gr00t_finetune.py", line 315, in <module>
    main(config)
  File "/workspace/Isaac-GR00T/scripts/gr00t_finetune.py", line 287, in main
    experiment.train()
  File "/workspace/Isaac-GR00T/gr00t/experiment/runner.py", line 173, in train
    self.trainer.train(resume_from_checkpoint=self.resume_from_checkpoint)
  File "/workspace/Isaac-GR00T/gr00t/experiment/trainer.py", line 153, in train
    return super().train(resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)
  File "/venv/gr00t/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/venv/gr00t/lib/python3.10/site-packages/transformers/trainer.py", line 2514, in _inner_training_loop
    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
  File "/venv/gr00t/lib/python3.10/site-packages/transformers/trainer.py", line 5243, in get_batch_samples
    batch_samples.append(next(epoch_iterator))
  File "/venv/gr00t/lib/python3.10/site-packages/accelerate/data_loader.py", line 552, in __iter__
    current_batch = next(dataloader_iter)
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1465, in _next_data
    return self._process_data(data)
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/venv/gr00t/lib/python3.10/site-packages/torch/_utils.py", line 714, in reraise
    raise RuntimeError(msg) from None
RuntimeError: Caught MemoryError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 508, in __getitem__
    return self.transforms(self.get_step_data(trajectory_id, base_index))
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 542, in get_step_data
    data[key] = self.get_data_by_modality(trajectory_id, modality, key, base_index)
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 802, in get_data_by_modality
    return self.get_video(trajectory_id, key, base_index)
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 672, in get_video
    return get_frames_by_timestamps(
  File "/workspace/Isaac-GR00T/gr00t/utils/video.py", line 112, in get_frames_by_timestamps
    for frame in reader:
  File "/venv/gr00t/lib/python3.10/site-packages/torchvision/io/video_reader.py", line 200, in __next__
    frame = next(self._c)
  File "av/container/input.pyx", line 208, in decode
  File "av/packet.pyx", line 80, in av.packet.Packet.decode
  File "av/video/stream.pyx", line 41, in av.video.stream.VideoStream.decode
  File "av/video/stream.pyx", line 50, in av.video.stream.VideoStream.decode
  File "av/codec/context.pyx", line 462, in av.codec.context.CodecContext.decode
  File "av/codec/context.pyx", line 238, in av.codec.context.CodecContext.open
  File "av/error.pyx", line 326, in av.error.err_check
av.error.MemoryError: [Errno 12] Cannot allocate memory
```

**è§£æ±ºç­–:** PyAVãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æœ€æ–°ç‰ˆã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§è§£æ±ºã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

```sh
pip install -U av
```

## å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

å­¦ç¿’ãŒå®Œäº†ã—ãŸã‚‰ã€ç”Ÿæˆã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’Hugging Face Hubã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

```sh
cd so101-checkpoints/checkpoint-5000/

# ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ (ä»»æ„)
# rm -rf scheduler.pt optimizer.pt

# Hugging Face Hubã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
huggingface-cli upload \
      --repo-type model yuk6ra/so101-onetape-cleanup . \
      --commit-message="Finetuned model with 5000 steps"
```

**NOTE**:ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã‚’åˆ©ç”¨ã—ãŸå ´åˆã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ãŸã‚‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å‰Šé™¤ã‚’å¿˜ã‚Œãªã„ã‚ˆã†ã«ã—ã¾ã—ã‚‡ã†ã€‚

# æ¨è«–ç·¨

ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ã€å®Ÿæ©Ÿãƒ­ãƒœãƒƒãƒˆã‚’å‹•ã‹ã—ã¾ã™ã€‚æ¨è«–ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ›ã‚¹ãƒˆã™ã‚‹**æ¨è«–ã‚µãƒ¼ãƒãƒ¼**ã¨ã€ãƒ­ãƒœãƒƒãƒˆã‚’åˆ¶å¾¡ã™ã‚‹**ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒãƒ¼ãƒ‰**ã®2ã¤ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚

## æ¨è«–ã‚µãƒ¼ãƒãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨å®Ÿè¡Œ

æ¨è«–ã‚µãƒ¼ãƒãƒ¼ã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«ã¾ãŸã¯ã‚¯ãƒ©ã‚¦ãƒ‰ã®GPUãƒã‚·ãƒ³ã§å®Ÿè¡Œã—ã¾ã™ã€‚ä»Šå›ã¯ä»¥ä¸‹ã®ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚

-   **GPU**: NVIDIA GeForce RTX 4070 Ti (12GB)
-   **RAM**: 128GB
-   **OS**: Ubuntu 22.04

ã‚¯ãƒ©ã‚¦ãƒ‰ã§å®Ÿè¡Œã™ã‚‹å ´åˆã¯ã€æ¨è«–ã‚µãƒ¼ãƒãƒ¼ç”¨ã®ãƒãƒ¼ãƒˆï¼ˆä¾‹: `5555`ï¼‰ã‚’é–‹ã‘ã¦ãŠãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

ã¾ãšã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã¨åŒæ§˜ã«GR00Tã®ç’°å¢ƒã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚æ¬¡ã«ã€Hugging Face Hubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™ã€‚

```sh
# GR00Tç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— (ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç·¨ã‚’å‚ç…§)
git clone https://github.com/NVIDIA/Isaac-GR00T
cd Isaac-GR00T
conda create -n gr00t python=3.10
conda activate gr00t
pip install --upgrade setuptools
pip install -e .[base]
pip install --no-build-isolation flash-attn==2.7.1.post4

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
huggingface-cli download \
     --repo-type model yuk6ra/so101-onetape-cleanup \
     --local-dir ./model/so101-onetape-cleanup

# æ¨è«–ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•
python scripts/inference_service.py \
    --model_path ./model/so101-onetape-cleanup \
    --embodiment_tag new_embodiment \
    --data_config so100_dualcam \
    --server \
    --port 5555
```

`Server is ready and listening on tcp://0.0.0.0:5555` ã¨è¡¨ç¤ºã•ã‚Œã‚Œã°èµ·å‹•æˆåŠŸã§ã™ã€‚

**NOTE:** ã“ã“ã§ã‚‚`data_config.py`ã®ã‚«ãƒ¡ãƒ©åã‚’`tip`ã«ä¿®æ­£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

#### ã‚¨ãƒ©ãƒ¼1: `OSError: CUDA_HOME environment variable is not set`

`flash-attn`ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ™‚ã«CUDAã®ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã«ç™ºç”Ÿã—ã¾ã™ã€‚

```shell:ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
Collecting flash-attn==2.7.1.post4
  Using cached flash_attn-2.7.1.post4.tar.gz (2.7 MB)
  Preparing metadata (setup.py) ... error
  error: subprocess-exited-with-error
  
  Ã— python setup.py egg_info did not run successfully.
  â”‚ exit code: 1
  â•°â”€> [20 lines of output]
      ...
      OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.
      ...
  [end of output]
```
**è§£æ±ºç­–:** `conda`ã§CUDA Toolkitã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```shell
conda install -c nvidia cuda-toolkit=12.4
```

#### ã‚¨ãƒ©ãƒ¼2: `ModuleNotFoundError: No module named 'flash_attn'`

**è§£æ±ºç­–:** `conda activate gr00t` ãŒæ­£ã—ãå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚æ„å›³ã›ãš`base`ã‚„`lerobot`ã®ç’°å¢ƒã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

## ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒãƒ¼ãƒ‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨å®Ÿè¡Œ

ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã€ãƒ‡ãƒ¼ã‚¿åé›†æ™‚ã«ä½¿ç”¨ã—ãŸ`lerobot`ã®ç’°å¢ƒã§å®Ÿè¡Œã—ã¾ã™ã€‚ã‚‚ã—ç’°å¢ƒãŒãªã„å ´åˆã¯ã€ä»¥ä¸‹ã®æ‰‹é †ã§ä½œæˆã—ã¾ã™ã€‚


```sh: lerobotã®ä»®æƒ³ç’°å¢ƒãŒãªã„å ´åˆ
# LeRobotãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/huggingface/lerobot.git
cd lerobot

# Condaç’°å¢ƒã‚’ä½œæˆã—ã¦æœ‰åŠ¹åŒ–
conda create -y -n lerobot python=3.10
conda activate lerobot

# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
conda install ffmpeg -c conda-forge
pip install -e .
pip install -e ".[feetech]"
```


```sh: lerobotã®ä»®æƒ³ç’°å¢ƒãŒã‚ã‚‹å ´åˆ
conda activate lerobot
```

`lerobot`ã®Condaç’°å¢ƒã‚’æœ‰åŠ¹åŒ–ã—ãŸã‚‰ã€ãã®ä»–ã«å¿…è¦ã«ãªã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```shell
pip install matplotlib
```

`Isaac-GR00T`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã—ã¾ã™ã€‚

```sh
cd ~/Documents/Isaac-GR00T/ # or your path to Isaac-GR00T
```

ã¾ãšã€`lerobot.find_cameras` ã‚’ä½¿ã£ã¦ã€ã‚·ã‚¹ãƒ†ãƒ ã«æ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‚«ãƒ¡ãƒ©ã®IDã‚’ç¢ºèªã—ã¾ã™ã€‚ã“ã®IDã¯å¾Œã»ã©ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆèµ·å‹•ã‚³ãƒãƒ³ãƒ‰ã®å¼•æ•°ã§ä½¿ç”¨ã—ã¾ã™ã€‚

```sh
$ python -m lerobot.find_cameras opencv
# ... (å®Ÿè¡Œçµæœã‹ã‚‰ tip ã¨ front ã«å¯¾å¿œã™ã‚‹ã‚«ãƒ¡ãƒ©IDã‚’ç¢ºèª)
# ä¾‹: tipãŒ2ã€frontãŒ0
```

æ¬¡ã«ã€`getting_started/examples/eval_lerobot.py`ã‚’GR00Tã®æ¨è«–æ©Ÿèƒ½ã¨é€£æºã•ã›ã‚‹ãŸã‚ã«ä¿®æ­£ã—ã¾ã™ã€‚

```diff:getting_started/examples/eval_lerobot.py
- from lerobot.common.cameras.opencv.configuration_opencv import (
+ from lerobot.cameras.opencv.configuration_opencv import (
    OpenCVCameraConfig,
)
- from lerobot.common.robots import (
+ from lerobot.robots import (
    Robot,
    RobotConfig,
    koch_follower,
    make_robot_from_config,
    so100_follower,
    so101_follower,
)
- from lerobot.common.utils.utils import (
+ from lerobot.utils.utils import (
    init_logging,
    log_say,
)

# NOTE:
# Sometimes we would like to abstract different env, or run this on a separate machine
# User can just move this single python class method gr00t/eval/service.py
# to their code or do the following line below
- # sys.path.append(os.path.expanduser("~/Isaac-GR00T/gr00t/eval/"))
+ import os 
+ import sys 
+ sys.path.append(os.path.expanduser("./gr00t/eval/")) # ãƒ‘ã‚¹ã®ä¿®æ­£
from service import ExternalRobotInferenceClient
```

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’èµ·å‹•ã—ã€ãƒ­ãƒœãƒƒãƒˆã«æŒ‡ç¤ºã‚’å‡ºã—ã¾ã™ã€‚

```shell: ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆ
python getting_started/examples/eval_lerobot.py \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM1 \
    --robot.id=white \
    --robot.cameras="{
        tip: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30},
        front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}
    }" \
    --lang_instruction="Grab the tape and place it in the box."
```

æ¨è«–ã‚µãƒ¼ãƒãƒ¼ã§ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹å ´åˆã¯ã€`--policy_host`ã¨`--policy_port`ã‚’ä»»æ„ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚

```shell: ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã®å ´åˆ
python getting_started/examples/eval_lerobot.py \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=white \
    --robot.cameras="{
        tip: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30},
        front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}
    }" \
    --policy_host xxx.xx.xx.xx \
    --policy_port xxxxx \
    --lang_instruction="Grab tapes and place into pen holder."
```

## å®Ÿè¡Œã®çµæœ

GR00T N1ã®å®Ÿè¡Œçµæœã§ã™ã€‚æ¯”è¼ƒã¨ã—ã¦ã€ACTãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸã¨å¤±æ•—ã®ä¾‹ã‚‚ç¤ºã—ã¦ãŠãã¾ã™ã€‚

### GR00T N1ï¼ˆæˆåŠŸï¼‰
https://youtu.be/x7jxNTNg8cU

### ACTï¼ˆæˆåŠŸï¼‰
https://youtu.be/pFOEiMeKiWQ

### GR00T N1ï¼ˆå¤±æ•—ï¼‰
https://youtu.be/CaIFHwCWR2w

### ACTï¼ˆå¤±æ•—ï¼‰
https://youtu.be/pCkPsHewTGk


### ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

#### ã‚¨ãƒ©ãƒ¼: æ¨è«–çµæœãŒ`Nan`ã«ãªã£ã¦ã„ãŸã‚Šã€ã‚«ã‚¯ã‚«ã‚¯å‹•ãã€‚

ãƒ¢ãƒ‡ãƒ«ã¯æ­£ã—ãã§ãã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ãŒã€ãƒ­ãƒœãƒƒãƒˆå´ã®å…¥åŠ›ãŒæ­£ã—ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

https://youtu.be/ggfFMOJ5QhE

**è§£æ±ºç­–:** `cameras`ã®è¨­å®šã‚’ç¢ºèªã—ãŸã‚Šã€ç’°å¢ƒæ§‹ç¯‰ã‚’å†åº¦ä½œã‚Šç›´ã—ã¦ã¿ã¦ãã ã•ã„ã€‚

# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ç·¨

æœ€å¾Œã«ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ã‚¿ã‚¹ã‚¯ã‚’ã©ã®ç¨‹åº¦å†ç¾ã§ãã‚‹ã‹ã‚’è©•ä¾¡ã—ã¾ã™ã€‚

## è©•ä¾¡ã®æº–å‚™

`gr00t`ç’°å¢ƒã§ä½œæ¥­ã—ã¾ã™ã€‚è©•ä¾¡ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€`modality.json`ã‚’æº–å‚™ã—ã¾ã™ã€‚ã“ã®æ‰‹é †ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã¨åŒæ§˜ã§ã™ã€‚

```sh
conda activate gr00t

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
huggingface-cli download \
       --repo-type dataset yuk6ra/so101-onetape-cleanup \
       --local-dir ./demo_data/so101-onetape-cleanup

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è©•ä¾¡ã™ã‚‹å ´åˆ --revision ã‚’ä½¿ç”¨)
huggingface-cli download \
    --repo-type model  yuk6ra/so101-onetape-cleanup \
    --local-dir ./model/so101-onetape-cleanup
    # --revision checkpoint-2000

# modality.jsonã®æº–å‚™
cp getting_started/examples/so100_dualcam__modality.json ./demo_data/so101-onetape-cleanup/meta/modality.json
# vimã§ã‚«ãƒ¡ãƒ©åã‚’ 'tip' ã«ä¿®æ­£
```

## è©•ä¾¡ã®å®Ÿè¡Œ

æº–å‚™ãŒã§ããŸã‚‰è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```sh
python scripts/eval_policy.py \
    --plot \
    --embodiment_tag new_embodiment \
    --model_path ./model/so101-onetape-cleanup/ \
    --data_config so100_dualcam \
    --dataset_path ./demo_data/so101-onetape-cleanup/ \
    --video_backend torchvision_av \
    --modality_keys single_arm gripper \
    --denoising_steps 4
```

**NOTE:** ã“ã“ã§ã‚‚`data_config.py`ã®ã‚«ãƒ¡ãƒ©åã‚’`tip`ã«ä¿®æ­£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

#### ã‚¨ãƒ©ãƒ¼: `ModuleNotFoundError: No module named 'tyro'`

**è§£æ±ºç­–:** ä»®æƒ³ç’°å¢ƒãŒ`gr00t`ã«ãªã£ã¦ã„ã‚‹ã‹ã€å†ç¢ºèªã—ã¦ãã ã•ã„ã€‚

## è©•ä¾¡çµæœ

å®Ÿè¡ŒãŒå®Œäº†ã™ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ï¼ˆPrediction: ç·‘ç·šï¼‰ã¨å®Ÿéš›ã®å‹•ä½œï¼ˆGround truth: ã‚ªãƒ¬ãƒ³ã‚¸ç·šï¼‰ã‚’æ¯”è¼ƒã—ãŸã‚°ãƒ©ãƒ•ãŒå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚°ãƒ©ãƒ•ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒã©ã®ç¨‹åº¦æ­£ç¢ºã«ã‚¿ã‚¹ã‚¯ã‚’å­¦ç¿’ã§ããŸã‹ã‚’è¦–è¦šçš„ã«ç¢ºèªã§ãã¾ã™ã€‚

![](/images/c474627fe7775b/plot.png)

## æ¯”è¼ƒæ¤œè¨

è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ´»ç”¨ã—ã€å­¦ç¿’ã®é€²æ—ã‚„ã‚¿ã‚¹ã‚¯ã®é›£æ˜“åº¦ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«ã©ã†å½±éŸ¿ã™ã‚‹ã‹ã‚’æ¯”è¼ƒæ¤œè¨ã—ã¾ã™ã€‚è©•ä¾¡çµæœã®ãƒ—ãƒ­ãƒƒãƒˆå›³ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ï¼ˆPrediction: ç·‘ç·šï¼‰ã¨å®Ÿéš›ã®å‹•ä½œï¼ˆGround truth: ã‚ªãƒ¬ãƒ³ã‚¸ç·šï¼‰ã®ã‚ºãƒ¬ã‚’å¯è¦–åŒ–ã—ãŸã‚‚ã®ã§ã€ä¸¡è€…ã®æ›²ç·šãŒè¿‘ã„ã»ã©ã€ãƒ¢ãƒ‡ãƒ«ãŒã‚¿ã‚¹ã‚¯ã‚’æ­£ç¢ºã«å†ç¾ã§ãã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚

### å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—æ•°ã«ã‚ˆã‚‹æ€§èƒ½æ¯”è¼ƒ

åŒã˜ã‚¿ã‚¹ã‚¯ï¼ˆ`onetape-cleanup`ï¼‰ã«å¯¾ã—ã¦ã€å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒ2000å›ã¨5000å›ã®å ´åˆã§æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚

#### 2000ã‚¹ãƒ†ãƒƒãƒ—æ™‚ç‚¹ã§ã®è©•ä¾¡

![](/images/c474627fe7775b/2000-onetape.png)

**è€ƒå¯Ÿ**: 2000ã‚¹ãƒ†ãƒƒãƒ—ã®æ™‚ç‚¹ã§ã¯ã€äºˆæ¸¬ï¼ˆç·‘ç·šï¼‰ãŒæ­£è§£ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ç·šï¼‰ã‚’å¤§ã¾ã‹ã«ã¯è¿½å¾“ã—ã¦ã„ã‚‹ã‚‚ã®ã®ã€å…¨ä½“çš„ã«ã‚ºãƒ¬ã‚„æŒ¯å‹•ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚ç‰¹ã«ã‚¢ãƒ¼ãƒ ã®å‹•ä½œï¼ˆ`single_arm`ï¼‰ã®æ¬¡å…ƒã«ã‚ˆã£ã¦ã¯ã€å‹•ããŒæ»‘ã‚‰ã‹ã§ãªãã€ã‚¿ã‚¹ã‚¯ã‚’å®Œå…¨ã«ã¯å†ç¾ã§ãã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚

#### 5000ã‚¹ãƒ†ãƒƒãƒ—æ™‚ç‚¹ã§ã®è©•ä¾¡

![](/images/c474627fe7775b/5000-onetape.png)

**è€ƒå¯Ÿ**: 5000ã‚¹ãƒ†ãƒƒãƒ—ã¾ã§å­¦ç¿’ã‚’é€²ã‚ã‚‹ã¨ã€äºˆæ¸¬ï¼ˆç·‘ç·šï¼‰ã¨æ­£è§£ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ç·šï¼‰ã®æ›²ç·šãŒã»ã¼ä¸€è‡´ã—ã€éå¸¸ã«æ»‘ã‚‰ã‹ã«å‹•ä½œã‚’å†ç¾ã§ãã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¿½åŠ ã®å­¦ç¿’ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ãŸã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚

### ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘ã•ã«ã‚ˆã‚‹æ€§èƒ½æ¯”è¼ƒ

æ¬¡ã«ã€åŒã˜5000ã‚¹ãƒ†ãƒƒãƒ—ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ã€ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘ã•ãŒæ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚

#### æœ€ã‚‚ç°¡å˜ãªã‚¿ã‚¹ã‚¯: `onetape-cleanup`

![](/images/c474627fe7775b/5000-onetape.png)

**è€ƒå¯Ÿ**: å‰è¿°ã®é€šã‚Šã€æœ€ã‚‚ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã§ã¯ãƒ¢ãƒ‡ãƒ«ã¯ã»ã¼å®Œç’§ã«å‹•ä½œã‚’å†ç¾ã§ãã¦ã„ã¾ã™ã€‚

#### ç°¡å˜ãªã‚¿ã‚¹ã‚¯: `tapes-cleanup`

![](/images/c474627fe7775b/5000-tapes.png)

**è€ƒå¯Ÿ**: ãƒ†ãƒ¼ãƒ—ãŒè¤‡æ•°ã«ãªã‚‹ã ã‘ã§ã€äºˆæ¸¬ï¼ˆç·‘ç·šï¼‰ã®ã‚ºãƒ¬ãŒå°‘ã—å¤§ãããªã‚Šã¾ã™ã€‚
#### è¤‡é›‘ãªã‚¿ã‚¹ã‚¯: `pen-cleanup`

![](/images/c474627fe7775b/5000-pen.png)

**è€ƒå¯Ÿ**: å…¬å¼ãƒ–ãƒ­ã‚°ã«è¼‰ã£ã¦ã„ã‚‹ãƒšãƒ³ã‚’ç‰‡ä»˜ã‘ã‚‹ã¨ã„ã†ã€ã‚ˆã‚Šè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«ãªã‚‹ã¨ã€äºˆæ¸¬ï¼ˆç·‘ç·šï¼‰ã¨æ­£è§£ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ç·šï¼‰ã®ä¹–é›¢ãŒé¡•è‘—ã«ãªã‚Šã¾ã™ã€‚ç‰¹å®šã®é–¢ç¯€ã®å‹•ãï¼ˆ`single_arm_4`ãªã©ï¼‰ã§å¤§ããªã‚ºãƒ¬ãŒç”Ÿã˜ã¦ãŠã‚Šã€5000ã‚¹ãƒ†ãƒƒãƒ—ã®å­¦ç¿’ã§ã¯ã“ã®è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã™ã‚‹ã«ã¯ä¸ååˆ†ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã™ã€‚

### ã•ã‚‰ãªã‚‹å­¦ç¿’ã®åŠ¹æœï¼ˆ7000ã‚¹ãƒ†ãƒƒãƒ—ï¼‰

è¤‡é›‘ãª`pen-cleanup`ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã€ã•ã‚‰ã«å­¦ç¿’ã‚’é€²ã‚ãŸ7000ã‚¹ãƒ†ãƒƒãƒ—æ™‚ç‚¹ã§ã®è©•ä¾¡ã‚‚è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

![](/images/c474627fe7775b/7000-pen.png)

**è€ƒå¯Ÿ**: 5000ã‚¹ãƒ†ãƒƒãƒ—ã¨æ¯”è¼ƒã—ã¦ã€7000ã‚¹ãƒ†ãƒƒãƒ—ã¾ã§å­¦ç¿’ã‚’é€²ã‚ã¦ã‚‚ã€ä¾ç„¶ã¨ã—ã¦äºˆæ¸¬ï¼ˆç·‘ç·šï¼‰ã¨æ­£è§£ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ç·šï¼‰ã®é–“ã«ã¯å¤§ããªä¹–é›¢ãŒæ®‹ã‚Šã€ã‚€ã—ã‚MSEã¯é«˜ããªã£ã¦ã„ã¾ã™ã®ã§ã€äºˆæ¸¬ãŒæ­£è§£ã‹ã‚‰é ã–ã‹ã‚Šã¾ã—ãŸã€‚ã“ã‚Œã¯ã€å˜ç´”ã«å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ã‚’å¢—ã‚„ã™ã ã‘ã§ã¯è§£æ±ºã§ããªã„å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¤šæ§˜æ€§ã‚„é‡ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€ã‚ã‚‹ã„ã¯ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è‡ªä½“ãŒã“ã®ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘ã•ã«å¯¾å¿œã—ãã‚Œã¦ã„ãªã„ã€ã¨ã„ã£ãŸå¯èƒ½æ€§ã‚‚è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚

ã“ã‚Œã‚‰ã®æ¯”è¼ƒã‹ã‚‰ã¯ã€æ”¹ã‚ã¦**ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘ã•ã«å¿œã˜ãŸååˆ†ãªå­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¨ã€è³ªã®é«˜ã„å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¿…è¦**ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚

# ã¾ã¨ã‚

æœ¬è¨˜äº‹ã§ã¯ã€LeRobotã§åé›†ã—ãŸç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦NVIDIA GR00T N1ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€å®Ÿæ©Ÿã§æ¨è«–ãƒ»è©•ä¾¡ã‚’è¡Œã†ã¾ã§ã®ä¸€é€£ã®æµã‚Œã‚’ã€è©³ç´°ãªã‚³ãƒãƒ³ãƒ‰ã‚„ãƒ­ã‚°ã¨å…±ã«è§£èª¬ã—ã¾ã—ãŸã€‚

é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

-   **ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§**: ãƒ‡ãƒ¼ã‚¿åé›†æ™‚ï¼ˆLeRobotï¼‰ã¨å­¦ç¿’ãƒ»æ¨è«–æ™‚ï¼ˆGR00Tï¼‰ã§ã€ã‚«ãƒ¡ãƒ©åãªã©ã®å„ç¨®è¨­å®šã‚’ä¸€è‡´ã•ã›ã‚‹ã“ã¨ãŒæ¥µã‚ã¦é‡è¦ã§ã™ã€‚
-   **ç’°å¢ƒæ§‹ç¯‰**: `conda`ã«ã‚ˆã‚‹ä»®æƒ³ç’°å¢ƒã®åˆ†é›¢ã¨ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é©åˆ‡ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒæˆåŠŸã®éµã¨ãªã‚Šã¾ã™ã€‚
-   **ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**: ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ã‚ˆãèª­ã¿ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç›´æ¥ç·¨é›†ãªã©ã€ç‹¬è‡ªã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ã®å¯¾å¿œåŠ›ãŒå¿…è¦ã¨ãªã‚Šã¾ã™ã€‚

æœ¬è¨˜äº‹ãŒã€GR00Tã‚’ä½¿ã£ã¦ç‹¬è‡ªã®ãƒ­ãƒœãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹ç™ºã™ã‚‹éš›ã®ä¸€åŠ©ã¨ãªã‚Œã°å¹¸ã„ã§ã™ã€‚ä»Šå¾Œã¯ã€ã‚ˆã‚Šè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«æŒ‘æˆ¦ã—ãŸã‚Šã€å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤‰ãˆã¦ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ãŸã‚Šã¨ã„ã£ãŸç™ºå±•çš„ãªå–ã‚Šçµ„ã¿ã‚‚è€ƒãˆã‚‰ã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚

ä½•ã‹ãŠæ°—ã¥ãã®ç‚¹ã‚„é–“é•ã„ãªã©ãŒã‚ã‚Šã¾ã—ãŸã‚‰ã€ãŠæ°—è»½ã«ã”é€£çµ¡ãã ã•ã„ã€‚ã¿ãªã•ã‚“ã§ä¸€ç·’ã«ç››ã‚Šä¸Šã’ã¦ã„ãã¾ã—ã‚‡ã†ã€‚