---
title: "ã€GR00T N1 / LeRobotã€‘SO-ARM101ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã™ã‚‹æ–¹æ³•"
emoji: "ğŸ—‚"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: []
published: false
---

# æ¦‚è¦

NVIDIA GR00T N1ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã€‚ãã®å¾Œæ¨è«–ã‚’è¡Œã†ã€‚

å‚è€ƒæ–‡çŒ®
- https://github.com/NVIDIA/Isaac-GR00T/tree/d5984002e24d418872adc5822a5bbb1d6a9b4ddc
- https://github.com/huggingface/lerobot/tree/519b76110efeea55a4f919895d0029dc0df41e8b
- https://huggingface.co/blog/nvidia/gr00t-n1-5-so101-tuning
- https://github.com/NVIDIA/Isaac-GR00T

ãƒ‡ãƒ¼ã‚¿ã‚’

# ãƒ‡ãƒ¼ã‚¿åé›†ç·¨

Penã¯è¤‡é›‘ã§ã†ã¾ãè¡Œã‹ãªã‹ã£ãŸã®ã§ã€ã‚ˆã‚Šç°¡å˜ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å€‹äººçš„ã«ã¯æ¨å¥¨ã™ã‚‹ã€‚

LeRobotã§50ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ç›®å®‰ã«è¡Œãªã†ã€‚


è¤‡é›‘ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿
https://huggingface.co/spaces/lerobot/visualize_dataset?path=%2Fyuk6ra%2Fso101-pen-cleanup%2Fepisode_0

ç°¡å˜ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿
https://huggingface.co/spaces/lerobot/visualize_dataset?path=%2Fyuk6ra%2Fso101-tapes-cleanup%2Fepisode_0


# ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç·¨
- ARM: SO-ARM101
- DISK: 300GB
- RAM: 128GB
- CPU: 
- GPU: H100 SXM
- VRAM: 80GB
- Ubuntu 24.04
- Internet Upload Speed: 4Gbps
- Internet Download Speed: 4Gbps

ãƒã‚¤ãƒ³ãƒˆã€DISKã¯200GBãã‚‰ã„ã¯ã»ã—ã„ã€‚
Checkpointã«ã‚‚ã‚ˆã‚‹ã€‚


## ç’°å¢ƒç¢ºèª

ãƒªãƒ¢ãƒ¼ãƒˆã®sshã§æ¥ç¶šã™ã‚‹

```sh
ssh -p 30454 root@xxx.xxx.xxx.xx -L 8080:localhost:8080
```

#### RAM
```sh
$ free -h
               total        used        free      shared  buff/cache   available
Mem:           503Gi        34Gi       372Gi        47Mi       101Gi       469Gi
Swap:          8.0Gi       186Mi       7.8Gi
```

### GPU
```sh
$ nvidia-smi
Sun Jul 13 06:57:05 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:E4:00.0 Off |                    0 |
| N/A   47C    P0             73W /  700W |       1MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

### OS
```sh
$ lsb_release -d
No LSB modules are available.
Description:    Ubuntu 24.04.2 LTS
```

### Disk
```sh
$ df /home -h
Filesystem      Size  Used Avail Use% Mounted on
overlay         300G   90M  300G   1% /
```




## ç’°å¢ƒæ§‹ç¯‰

https://huggingface.co/spaces/lerobot/visualize_dataset


## å…¬å¼ã«ç¿’ã£ã¦


```sh
git clone https://github.com/NVIDIA/Isaac-GR00T
cd Isaac-GR00T
conda create -n gr00t python=3.10
conda activate gr00t
pip install --upgrade setuptools
pip install -e .[base]
pip install --no-build-isolation flash-attn==2.7.1.post4
```


## ãƒ­ã‚°ã‚¤ãƒ³

```sh
huggingface-cli login
```

ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚’å–ã‚‹

```sh
wandb login
```

https://wandb.ai/


## å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

```sh
huggingface-cli download \
       --repo-type dataset yuk6ra/so101-onetape-cleanup \
       --local-dir ./demo_data/so101-onetape-cleanup
```


```sh
cp getting_started/examples/so100_dualcam__modality.json ./demo_data/so101-onetape-cleanup/meta/modality.json
```

ä»Šå›ã¯
```sh
vim ./demo_data/so101-onetape-cleanup/meta/modality.json
```

```json
 {
        "state": {
            "single_arm": {
                "start": 0,
                "end": 5
            },
            "gripper": {
                "start": 5,
                "end": 6
            }
        },
        "action": {
            "single_arm": {
                "start": 0,
                "end": 5
            },
            "gripper": {
                "start": 5,
                "end": 6
            }
        },
        "video": {
            "front": {
                "original_key": "observation.images.front"
            },
            "tip": {ã€€// å¤‰æ›´
                "original_key": "observation.images.tip"  // å¤‰æ›´
            }
        },
        "annotation": {
            "human.task_description": {
                "original_key": "task_index"
            }
        }
    }
```

```
python scripts/load_dataset.py --dataset-path ./demo_data/so101-onetape-cleanup --plot-state-action --video-backend torchvision_av
```

```sh
====================================================================================================
========================================= Humanoid Dataset =========================================
====================================================================================================
{'action.gripper': 'np scalar: 1.1111111640930176 [1, 1] float64',
 'action.single_arm': 'np: [1, 5] float64',
 'annotation.human.task_description': ['Grab the tape and place it in the '
                                       'box.'],
 'state.gripper': 'np scalar: 2.410423517227173 [1, 1] float64',
 'state.single_arm': 'np: [1, 5] float64',
 'video.front': 'np: [1, 480, 640, 3] uint8',
 'video.tip': 'np: [1, 480, 640, 3] uint8'}
dict_keys(['video.front', 'video.tip', 'state.single_arm', 'state.gripper', 'action.single_arm', 'action.gripper', 'annotation.human.task_description'])
==================================================
video.front: (1, 480, 640, 3)
video.tip: (1, 480, 640, 3)
state.single_arm: (1, 5)
state.gripper: (1, 1)
action.single_arm: (1, 5)
action.gripper: (1, 1)
annotation.human.task_description: ['Grab the tape and place it in the box.']
Image 0, prompt: ['Grab the tape and place it in the box.']
Image 10, prompt: ['Grab the tape and place it in the box.']
Image 20, prompt: ['Grab the tape and place it in the box.']
Image 30, prompt: ['Grab the tape and place it in the box.']
Image 40, prompt: ['Grab the tape and place it in the box.']
Image 50, prompt: ['Grab the tape and place it in the box.']
Image 60, prompt: ['Grab the tape and place it in the box.']
Image 70, prompt: ['Grab the tape and place it in the box.']
Image 80, prompt: ['Grab the tape and place it in the box.']
Image 90, prompt: ['Grab the tape and place it in the box.']
Image 100, prompt: ['Grab the tape and place it in the box.']
Image 110, prompt: ['Grab the tape and place it in the box.']
Image 120, prompt: ['Grab the tape and place it in the box.']
Image 130, prompt: ['Grab the tape and place it in the box.']
Image 140, prompt: ['Grab the tape and place it in the box.']
Image 150, prompt: ['Grab the tape and place it in the box.']
Image 160, prompt: ['Grab the tape and place it in the box.']
Image 170, prompt: ['Grab the tape and place it in the box.']
Image 180, prompt: ['Grab the tape and place it in the box.']
Image 190, prompt: ['Grab the tape and place it in the box.']
Warning: Skipping left_arm as it's not found in both state and action dictionaries
Warning: Skipping right_arm as it's not found in both state and action dictionaries
Warning: Skipping left_hand as it's not found in both state and action dictionaries
Warning: Skipping right_hand as it's not found in both state and action dictionaries
Plotted state and action space
```

```sh
vim ./gr00t/experiment/data_config.py
```

225è¡Œç›®ã‚ãŸã‚Šã€‚
```python
class So100DualCamDataConfig(So100DataConfig):
     - video_keys = ["video.front", "video.wrist"]
     + video_keys = ["video.front", "video.tip"]
      	state_keys = ["state.single_arm", "state.gripper"]
       action_keys = ["action.single_arm", "action.gripper"]
       language_keys = ["annotation.human.task_description"]
       observation_indices = [0]
       action_indices = list(range(16))
```


## å­¦ç¿’ã•ã›ã‚‹

H100ã§30åˆ†ã»ã©æ”¾ç½®ã€‚
MAX5000ã‚¹ãƒ†ãƒƒãƒ—ã§100GBã»ã©ã‚’æ¶ˆè²»ã€‚

```sh
python scripts/gr00t_finetune.py \
      --dataset-path ./demo_data/so101-onetape-cleanup/ \
      --num-gpus 1 \
      --output-dir ./so101-checkpoints  \
      --max-steps 5000 \
      --data-config so100_dualcam \
      --video-backend torchvision_av
```


### ã‚¨ãƒ©ãƒ¼â‘ 
ã‚‚ã—ä¸‹è¨˜ã®ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ãŒã§ã‚‹ãªã‚‰ã€‚
```sh
  0%|                                                                                                                            | 0/5000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/workspace/Isaac-GR00T/scripts/gr00t_finetune.py", line 315, in <module>
    main(config)
  File "/workspace/Isaac-GR00T/scripts/gr00t_finetune.py", line 287, in main
    experiment.train()
  File "/workspace/Isaac-GR00T/gr00t/experiment/runner.py", line 173, in train
    self.trainer.train(resume_from_checkpoint=self.resume_from_checkpoint)
  File "/workspace/Isaac-GR00T/gr00t/experiment/trainer.py", line 153, in train
    return super().train(resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)
  File "/venv/gr00t/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/venv/gr00t/lib/python3.10/site-packages/transformers/trainer.py", line 2514, in _inner_training_loop
    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
  File "/venv/gr00t/lib/python3.10/site-packages/transformers/trainer.py", line 5243, in get_batch_samples
    batch_samples.append(next(epoch_iterator))
  File "/venv/gr00t/lib/python3.10/site-packages/accelerate/data_loader.py", line 552, in __iter__
    current_batch = next(dataloader_iter)
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1465, in _next_data
    return self._process_data(data)
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/venv/gr00t/lib/python3.10/site-packages/torch/_utils.py", line 714, in reraise
    raise RuntimeError(msg) from None
RuntimeError: Caught MemoryError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 508, in __getitem__
    return self.transforms(self.get_step_data(trajectory_id, base_index))
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 542, in get_step_data
    data[key] = self.get_data_by_modality(trajectory_id, modality, key, base_index)
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 802, in get_data_by_modality
    return self.get_video(trajectory_id, key, base_index)
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 672, in get_video
    return get_frames_by_timestamps(
  File "/workspace/Isaac-GR00T/gr00t/utils/video.py", line 112, in get_frames_by_timestamps
    for frame in reader:
  File "/venv/gr00t/lib/python3.10/site-packages/torchvision/io/video_reader.py", line 200, in __next__
    frame = next(self._c)
  File "av/container/input.pyx", line 208, in decode
  File "av/packet.pyx", line 80, in av.packet.Packet.decode
  File "av/video/stream.pyx", line 41, in av.video.stream.VideoStream.decode
  File "av/video/stream.pyx", line 50, in av.video.stream.VideoStream.decode
  File "av/codec/context.pyx", line 462, in av.codec.context.CodecContext.decode
  File "av/codec/context.pyx", line 238, in av.codec.context.CodecContext.open
  File "av/error.pyx", line 326, in av.error.err_check
av.error.MemoryError: [Errno 12] Cannot allocate memory
```

ã„ã£ãŸã‚“PyAVã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹
```sh
pip install -U av
```

### ã‚¨ãƒ©ãƒ¼â‘¡



## HFã¸ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
```sh
cd so101-checkpoints/checkpoint-5000/
huggingface-cli upload yuk6ra/so101-onetape-cleanup . --commit-message="2000 step"
```

# æ¨è«–ç·¨ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰
æ¨è«–ã‚µãƒ¼ãƒãƒ¼ã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µãƒ¼ãƒãƒ¼ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚

## ç’°å¢ƒæ§‹ç¯‰

```sh
git clone https://github.com/NVIDIA/Isaac-GR00T
cd Isaac-GR00T
conda create -n gr00t python=3.10
conda activate gr00t
pip install --upgrade setuptools
pip install -e .[base]
pip install --no-build-isolation flash-attn==2.7.1.post4
```

## ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

æ¨è«–ã‚µãƒ¼ãƒãƒ¼ãŒåˆ¥PCã§ã‚ã‚Œã°ã€ã‚‚ã†ä¸€åº¦GR00T N1ã®ç’°å¢ƒã‚’ã¤ãã‚‹ã€‚

åŒæ§˜ã®ç’°å¢ƒã‚’ä½œã‚‹ã€‚



```sh
huggingface-cli login
huggingface-cli download yuk6ra/so101-onetape-cleanup --repo-type model --local-dir ./model/so101-onetape-cleanup
```

### 

code:gr00t/experiment/data_config.pyã«ã¯æ³¨æ„ã™ã‚‹ã€‚

225è¡Œç›®

```python
class So100DualCamDataConfig(So100DataConfig):
- video_keys = ["video.front", "video.wrist"]
+ video_keys = ["video.front", "video.tip"]
    state_keys = ["state.single_arm", "state.gripper"]
    action_keys = ["action.single_arm", "action.gripper"]
    language_keys = ["annotation.human.task_description"]
    observation_indices = [0]
    action_indices = list(range(16))
```


## è©•ä¾¡ã™ã‚‹

```sh
huggingface-cli download \
       --repo-type dataset yuk6ra/so101-onetape-cleanup \
       --local-dir ./demo_data/so101-onetape-cleanup
cp getting_started/examples/so100_dualcam__modality.json ./demo_data/so101-onetape-cleanup/meta/modality.json
vim ./demo_data/so101-onetape-cleanup/meta/modality.json
```
æ²»ã™ã€‚

```sh
python scripts/eval_policy.py --plot \
       --embodiment_tag new_embodiment \
       --model_path ./model/so101-onetape-cleanup/ \
       --data_config so100_dualcam \
       --dataset_path ./demo_data/so101-onetape-cleanup/ \
       --video_backend torchvision_av \
       --modality_keys single_arm gripper \
       --denoising_steps 4
```

## æ¨è«–ã‚µãƒ¼ãƒãƒ¼ã®ç«‹ã¡ä¸Šã’
### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ
- 4070 Ti 12GB

```sh
$ nvidia-smi
Sun Jul 13 19:45:37 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.153.02             Driver Version: 570.153.02     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4070 Ti     Off |   00000000:01:00.0  On |                  N/A |
|  0%   34C    P8              6W /  285W |     682MiB /  12282MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A            2453      G   /usr/lib/xorg/Xorg                      309MiB |
|    0   N/A  N/A            2608      G   /usr/bin/gnome-shell                     70MiB |
|    0   N/A  N/A            3211      G   /opt/brave.com/brave/brave                3MiB |
|    0   N/A  N/A            3254      G   ...c0b8c13d56e6779503f2cc987a424        119MiB |
|    0   N/A  N/A            5526      G   ...ess --variations-seed-version        125MiB |
+-----------------------------------------------------------------------------------------+
```


```sh
$ lsb_release -d
Description:	Ubuntu 22.04.5 LTS
```

ç«‹ã¡ä¸Šã’ã‚‹
```sh
python scripts/inference_service.py --model_path ./model/so101-onetape-cleanup --embodiment_tag new_embodiment --data_config so100_dualcam --server --port 5555
```


####ã€€ã‚¨ãƒ©ãƒ¼
```sh
pip install --no-build-isolation flash-attn==2.7.1.post4 

Collecting flash-attn==2.7.1.post4
  Using cached flash_attn-2.7.1.post4.tar.gz (2.7 MB)
  Preparing metadata (setup.py) ... error
  error: subprocess-exited-with-error
  
  Ã— python setup.py egg_info did not run successfully.
  â”‚ exit code: 1
  â•°â”€> [20 lines of output]
      fatal: not a git repository (or any of the parent directories): .git
      /tmp/pip-install-myxzi7su/flash-attn_3ea6f071d2e84485a9e98af6137eb7b7/setup.py:99: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.
        warnings.warn(
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 35, in <module>
        File "/tmp/pip-install-myxzi7su/flash-attn_3ea6f071d2e84485a9e98af6137eb7b7/setup.py", line 184, in <module>
          CUDAExtension(
        File "/home/yuk6ra/anaconda3/envs/gr00t/lib/python3.10/site-packages/torch/utils/cpp_extension.py", line 1078, in CUDAExtension
          library_dirs += library_paths(cuda=True)
        File "/home/yuk6ra/anaconda3/envs/gr00t/lib/python3.10/site-packages/torch/utils/cpp_extension.py", line 1209, in library_paths
          if (not os.path.exists(_join_cuda_home(lib_dir)) and
        File "/home/yuk6ra/anaconda3/envs/gr00t/lib/python3.10/site-packages/torch/utils/cpp_extension.py", line 2416, in _join_cuda_home
          raise OSError('CUDA_HOME environment variable is not set. '
      OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.
      
      
      torch.__version__  = 2.5.1+cu124
      
      
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

Ã— Encountered error while generating package metadata.
â•°â”€> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
```

ã“ã‚Œã‚’å…¥ã‚Œã‚‹
```
conda install -c nvidia cuda-toolkit=12.4
```

### ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒ

### ã‚¨ãƒ©ãƒ¼
ã‚‚ã—`ModuleNotFoundError: No module named 'flash_attn'`ãŒå‡ºãŸã‚‰ã€ä»®æƒ³ç’°å¢ƒãŒ`gr00t`ã§ã¯ãªã`lerobot`ã‚„`base`ã®ç’°å¢ƒã«ãªã£ã¦ã„ãªã„ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚

## ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µãƒ¼ãƒãƒ¼ã®ç«‹ã¡ä¸Šã’

æ³¨æ„ï¼šLeRobotã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨äº’æ›æ€§ã‚’ä¿ã¤å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚



lerobotã®ç’°å¢ƒã‚’ã¤ãã‚‹ã‚„ã‚‹ã€‚ã‚‚ã†ã™ã§ã«ã‚ã‚Œã°OKã§å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ãŸã¨ãã®ã‚‚ã®ã§OKã€‚

```sh
git clone https://github.com/huggingface/lerobot.git
cd lerobot
conda create -y -n lerobot python=3.10
conda activate lerobot
conda install ffmpeg -c conda-forge
pip install -e .
pip install -e ".[feetech]"
```

å‚è€ƒæ–‡çŒ®ï¼šhttps://huggingface.co/docs/lerobot/installation


ã“ã®ã¨ãlerobot ã®ãƒ•ã‚©ãƒ«ãƒ€ã ã¨æ€ã„ã¾ã™ãŒã€
Isaac-GR00Tã®ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•ã—ã¦ç’°å¢ƒã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã€‚

```sh
d ~/Documents/Isaac-GR00T/
conda activate lerobot
```

ã•ã‚‰ã«è¿½åŠ ã§ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨gr00tã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‚
```sh
pip install matplotlib

pip install --upgrade setuptools
pip install -e .[base]
pip install --no-build-isolation flash-attn==2.7.1.post4
```


`outputs/captured_images`ä»¥ä¸‹ã§ã‚«ãƒ¡ãƒ©ã®IDã‚’ãƒ¡ãƒ¢ã—ã¦ãŠãã€‚
```sh
python -m lerobot.find_cameras opencv
```

`getting_started/examples/eval_lerobot.py`ã§ã€lerobotã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒã‚ã£ã¦ã„ãªã„ã®ã§`common`ã‚’æ¶ˆã™ã€‚

```python
from lerobot.cameras.opencv.configuration_opencv import ( # <---commonã‚’æ¶ˆã™
    OpenCVCameraConfig,
)
from lerobot.robots import ( # <---commonã‚’æ¶ˆã™
    Robot,model/so101-tapes-cleanup-2000
    RobotConfig,
    koch_follower,
    make_robot_from_config,
    so100_follower,
    so101_follower,
)
from lerobot.utils.utils import ( # <---commonã‚’æ¶ˆã™
    init_logging,
    log_say,
)

...
# from service import ExternalRobotInferenceClient # <--- ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ

from gr00t.eval.service import ExternalRobotInferenceClient # <--- 
```

å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚
```
pip install matplotlib
```


```sh
python getting_started/examples/eval_lerobot.py \
         --robot.type=so101_follower \
         --robot.port=/dev/ttyACM1 \
         --robot.id=white \
         --robot.cameras="{
             tip: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30},
             front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}
         }" \
         --lang_instruction="Grab the tape and place it in the box."
```

### ã‚¯ãƒ©ã‚¦ãƒ‰å‘ã‘

ã‚¤ãƒ¡ãƒ¼ã‚¸ãªã©ã«ä¸‹è¨˜ã®ãƒãƒ¼ãƒˆã‚’ã‚ã‘ã¦ãã ã•ã„ã€‚
```
-p 5555:5555
```

```sh
python getting_started/examples/eval_lerobot.py \
       --robot.type=so101_follower \
       --robot.port=/dev/ttyACM0 \
       --robot.id=white \
       --robot.cameras="{
           tip: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30},
           front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}
       }" \
       --policy_host 194.14.47.19 \ # è¿½åŠ 
       --policy_port 22037 \ # è¿½åŠ 
       --lang_instruction="Grab tapes and place into pen holder."
```


# è©•ä¾¡ç·¨



# ã¾ã¨ã‚
