---
title: "ã€GR00T N1 / LeRobotã€‘SO-ARM101ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã™ã‚‹æ–¹æ³•"
emoji: "ğŸ—‚"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: []
published: false
---

# æ¦‚è¦

ãƒ‡ãƒ¢ã€‚

NVIDIA GR00T N1ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã€‚ãã®å¾Œæ¨è«–ã‚’è¡Œã†ã€‚

å‚è€ƒæ–‡çŒ®
- https://github.com/NVIDIA/Isaac-GR00T/tree/d5984002e24d418872adc5822a5bbb1d6a9b4ddc
- https://github.com/huggingface/lerobot/tree/519b76110efeea55a4f919895d0029dc0df41e8b
- https://huggingface.co/blog/nvidia/gr00t-n1-5-so101-tuning
- https://github.com/NVIDIA/Isaac-GR00T

ãƒ‡ãƒ¼ã‚¿ã‚’

# ãƒ‡ãƒ¼ã‚¿åé›†ç·¨

Penã¯è¤‡é›‘ã§ã†ã¾ãè¡Œã‹ãªã‹ã£ãŸã®ã§ã€ã‚ˆã‚Šç°¡å˜ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å€‹äººçš„ã«ã¯æ¨å¥¨ã™ã‚‹ã€‚

LeRobotã§50ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ç›®å®‰ã«è¡Œãªã†ã€‚ä»Šå›ã¯ä¸€ç•ªç°¡å˜ãªãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†ã€‚

## ã‚¿ã‚¹ã‚¯ã®ç¨®é¡
### **â‘ è¤‡é›‘ãªã‚¿ã‚¹ã‚¯**: `so101-pen-cleanup`
- 

https://huggingface.co/spaces/lerobot/visualize_dataset?path=%2Fyuk6ra%2Fso101-pen-cleanup%2Fepisode_0

### ç°¡å˜ãªã‚¿ã‚¹ã‚¯:  `so101-tapes-cleanup`
- ã‚¿ã‚¤ãƒ—: ç°¡å˜ãªã‚¿ã‚¹ã‚¯

https://huggingface.co/spaces/lerobot/visualize_dataset?path=%2Fyuk6ra%2Fso101-tapes-cleanup%2Fepisode_0

### æœ€ã‚‚ç°¡å˜ãªã‚¿ã‚¹ã‚¯:`so101-onetape-cleanup`

https://huggingface.co/spaces/lerobot/visualize_dataset?path=%2Fyuk6ra%2Fso101-onetape-cleanup%2Fepisode_0


ãªãŠã€ä¸‹è¨˜ã®ã‚ˆã†ãªè¨­å®šã§å–å¾—ã—ã¦ã„ã‚‹ã€‚
ã‚«ãƒ¡ãƒ©è¨­å®šã§ã¯ã€ãƒ­ãƒœãƒƒãƒˆè¦–ç‚¹ã§ã®
- `tip`: å…ˆç«¯ã®ã‚«ãƒ¡ãƒ©
- `front`: å‰æ–¹ã®ã‚«ãƒ¡ãƒ©
ã‚’ç”¨æ„ã—ãŸã€‚ã‚«ãƒ¡ãƒ©ã®åç§°ãŒå¾Œã€…é–¢ã‚ã£ã¦ãã‚‹ã®ã§æ³¨æ„ã™ã‚‹ã€‚`wrist`ã¨`front`ã§ã‚ã‚Œã°ãã®ã¾ã¾ã§ä½¿ãˆã‚‹ã€‚

```yaml
dataset:
  repo_id: "yuk6ra/so101-onetape-cleanup"  # Hugging Face ã®ãƒªãƒã‚¸ãƒˆãƒªID
  single_task: "Grab the tape and place it in the box."  # ã‚¿ã‚¹ã‚¯ã®èª¬æ˜
  num_episodes: 50  # è¨˜éŒ²ã™ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°
  fps: 30  # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ
  episode_time_s: 15  # 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§æ™‚é–“ï¼ˆç§’ï¼‰
  reset_time_s: 15  # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜éŒ²å¾Œã®ãƒªã‚»ãƒƒãƒˆæ™‚é–“ï¼ˆç§’ï¼‰

# ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã‚¢ãƒ¼ãƒ 
robot:
  type: "so101_follower"
  port: "/dev/ttyACM0"  # ã‚·ãƒªã‚¢ãƒ«ãƒãƒ¼ãƒˆ
  id: "white"  # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã®ID
  
  # ã‚«ãƒ¡ãƒ©è¨­å®š
  cameras:
    tip:
      type: "opencv"
      index_or_path: 0
      fps: 30
      width: 640
      height: 480
    front:
      type: "opencv"
      index_or_path: 2
      fps: 30
      width: 640
      height: 480

# ãƒªãƒ¼ãƒ€ãƒ¼ã‚¢ãƒ¼ãƒ 
teleop:
  type: "so101_leader" 
  port: "/dev/ttyACM1"  # ã‚·ãƒªã‚¢ãƒ«ãƒãƒ¼ãƒˆ
  id: "black"  # ãƒªãƒ¼ãƒ€ãƒ¼ã®ID

# è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³
options:
  display_data: false  # ã‚«ãƒ¡ãƒ©æ˜ åƒã‚’è¡¨ç¤ºã™ã‚‹ã‹
  push_to_hub: true # Hugging Face Hub ã«è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹
```

# ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç·¨

## GPUã‚’å€Ÿã‚Šã‚‹
ã‚‚ã—è‡ªåˆ†ã®ã‚‚ã®ãŒã‚ã‚Œã°è‰¯ã„ã€‚

ã‚¹ãƒšãƒƒã‚¯ã¯ã€ä¸‹è¨˜ã€‚
- GPU: H100 SXM
    - VRAM: 80GB
- DISK: 300GB
- RAM: 128GBä»¥ä¸Š
- OSï¼šUbuntu 24.04
- ãƒãƒƒãƒˆé€Ÿåº¦
    - Internet Upload Speed: 4Gbps
    - Internet Download Speed: 4Gbps

DISKã¯200GBãã‚‰ã„ã¯ã»ã—ã„ã€‚Checkpointã«ã‚‚ã‚ˆã‚‹ã€‚
ä»Šå›ã¯5000ã‚¹ãƒ†ãƒƒãƒ—ã§ã€ç´„100GBã‚’æ¶ˆè²»ã—ãŸã€‚

## PCç’°å¢ƒã®ç¢ºèª

ãƒªãƒ¢ãƒ¼ãƒˆã®sshã§æ¥ç¶šã™ã‚‹

```sh
ssh -p 30454 root@xxx.xxx.xxx.xx -L 8080:localhost:8080
```

### RAMã®ç¢ºèª
```sh
$ free -h
               total        used        free      shared  buff/cache   available
Mem:           503Gi        34Gi       372Gi        47Mi       101Gi       469Gi
Swap:          8.0Gi       186Mi       7.8Gi
```

### GPUã®ç¢ºèª
```sh
$ nvidia-smi
Sun Jul 13 06:57:05 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:E4:00.0 Off |                    0 |
| N/A   47C    P0             73W /  700W |       1MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

### OSã®ç¢ºèª
```sh
$ lsb_release -d
No LSB modules are available.
Description:    Ubuntu 24.04.2 LTS
```

### ãƒ‡ã‚£ã‚¹ã‚¯ã®ç¢ºèª
```sh
$ df /home -h
Filesystem      Size  Used Avail Use% Mounted on
overlay         300G   90M  300G   1% /
```

## ä»®æƒ³ç’°å¢ƒã®æ§‹ç¯‰

https://huggingface.co/blog/nvidia/gr00t-n1-5-so101-tuning

å…¬å¼ã«ç¿’ã†ã€‚

```sh
# ã‚¯ãƒ­ãƒ¼ãƒ³ã™ã‚‹
git clone https://github.com/NVIDIA/Isaac-GR00T
cd Isaac-GR00T

# ç’°å¢ƒã‚’ã¤ãã‚‹
conda create -n gr00t python=3.10
conda activate gr00t
pip install --upgrade setuptools
pip install -e .[base]
pip install --no-build-isolation flash-attn==2.7.1.post4
```


## ãƒ­ã‚°ã‚¤ãƒ³
å„ç¨®ã‚µãƒ¼ãƒ“ã‚¹ã«å…ˆã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãŠãã€‚

### Hugging Face
Setting Pageã‚ˆã‚Š
https://huggingface.co/settings/tokens

```sh
huggingface-cli login
```

### Wandb
ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚’å–ã‚‹
https://wandb.ai/authorize


```sh
wandb login
```



## å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

è‡ªåˆ†ã«åˆã‚ã›ã¦ã€‚Huggingfaceã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚‚ã‚‰ã£ã¦ãã‚‹ã€‚

```sh
huggingface-cli download \
       --repo-type dataset yuk6ra/so101-onetape-cleanup \
       --local-dir ./demo_data/so101-onetape-cleanup
```

GR00Täº’æ›ã«ã™ã‚‹ãŸã‚ã«`modality.json`ãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®`/meta/`ä»¥ä¸‹ã«å¿…è¦ã§ã™ã€‚ä»Šå›ã¯ãƒ‡ãƒ¥ã‚¢ãƒ«ã‚«ãƒ¡ãƒ©ã‚’ç”¨ã„ã¦ã„ã¾ã™ã€‚

```sh
cp getting_started/examples/so100_dualcam__modality.json ./demo_data/so101-onetape-cleanup/meta/modality.json
```

ãã—ã¦ã€`modality.json`ãŒ`wrist`ã‹ã‚‰
```sh
vim ./demo_data/so101-onetape-cleanup/meta/modality.json
```

```json
 {
    ...
        "video": {
            "front": {
                "original_key": "observation.images.front"
            },
            "tip": {ã€€// `wrist`ã‹ã‚‰`tip`ã¸å¤‰æ›´
                "original_key": "observation.images.tip"  // `wrist`ã‹ã‚‰`tip`ã¸å¤‰æ›´
            }
        },
    ...
```

```shell
python scripts/load_dataset.py \
    --dataset-path ./demo_data/so101-onetape-cleanup \
    --plot-state-action \
    --video-backend torchvision_av
```

```sh
====================================================================================================
========================================= Humanoid Dataset =========================================
====================================================================================================
{'action.gripper': 'np scalar: 1.1111111640930176 [1, 1] float64',
 'action.single_arm': 'np: [1, 5] float64',
 'annotation.human.task_description': ['Grab the tape and place it in the '
                                       'box.'],
 'state.gripper': 'np scalar: 2.410423517227173 [1, 1] float64',
 'state.single_arm': 'np: [1, 5] float64',
 'video.front': 'np: [1, 480, 640, 3] uint8',
 'video.tip': 'np: [1, 480, 640, 3] uint8'}
dict_keys(['video.front', 'video.tip', 'state.single_arm', 'state.gripper', 'action.single_arm', 'action.gripper', 'annotation.human.task_description'])
==================================================
video.front: (1, 480, 640, 3)
video.tip: (1, 480, 640, 3)
state.single_arm: (1, 5)
state.gripper: (1, 1)
action.single_arm: (1, 5)
action.gripper: (1, 1)
annotation.human.task_description: ['Grab the tape and place it in the box.']
Image 0, prompt: ['Grab the tape and place it in the box.']
Image 10, prompt: ['Grab the tape and place it in the box.']
Image 20, prompt: ['Grab the tape and place it in the box.']
Image 30, prompt: ['Grab the tape and place it in the box.']
Image 40, prompt: ['Grab the tape and place it in the box.']
Image 50, prompt: ['Grab the tape and place it in the box.']
Image 60, prompt: ['Grab the tape and place it in the box.']
Image 70, prompt: ['Grab the tape and place it in the box.']
Image 80, prompt: ['Grab the tape and place it in the box.']
Image 90, prompt: ['Grab the tape and place it in the box.']
Image 100, prompt: ['Grab the tape and place it in the box.']
Image 110, prompt: ['Grab the tape and place it in the box.']
Image 120, prompt: ['Grab the tape and place it in the box.']
Image 130, prompt: ['Grab the tape and place it in the box.']
Image 140, prompt: ['Grab the tape and place it in the box.']
Image 150, prompt: ['Grab the tape and place it in the box.']
Image 160, prompt: ['Grab the tape and place it in the box.']
Image 170, prompt: ['Grab the tape and place it in the box.']
Image 180, prompt: ['Grab the tape and place it in the box.']
Image 190, prompt: ['Grab the tape and place it in the box.']
Warning: Skipping left_arm as it's not found in both state and action dictionaries
Warning: Skipping right_arm as it's not found in both state and action dictionaries
Warning: Skipping left_hand as it's not found in both state and action dictionaries
Warning: Skipping right_hand as it's not found in both state and action dictionaries
Plotted state and action space
```

## å­¦ç¿’ã•ã›ã‚‹

H100ã§30åˆ†ã»ã©æ”¾ç½®ã€‚
MAX5000ã‚¹ãƒ†ãƒƒãƒ—ã§100GBã»ã©ã‚’æ¶ˆè²»ã€‚

```sh
python scripts/gr00t_finetune.py \
      --dataset-path ./demo_data/so101-onetape-cleanup/ \
      --num-gpus 1 \
      --output-dir ./so101-checkpoints  \
      --max-steps 5000 \
      --data-config so100_dualcam \
      --video-backend torchvision_av
```

### ã‚¨ãƒ©ãƒ¼ï¼š`ValueError: Video key wrist not found in dataset metadata. Available keys: dict_keys(['front', 'tip'])`

ã‚‚ã—ã‚«ãƒ¡ãƒ©åç§°ãŒé•ã†ã€‚

```sh
vim ./gr00t/experiment/data_config.py
```

225è¡Œç›®ã‚ãŸã‚Šã€‚
```python
class So100DualCamDataConfig(So100DataConfig):
 -   video_keys = ["video.front", "video.wrist"]
 +  video_keys = ["video.front", "video.tip"]
```

### ã‚¨ãƒ©ãƒ¼â‘ : `av.error.MemoryError: [Errno 12] Cannot allocate memory`
ã‚‚ã—ä¸‹è¨˜ã®ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ãŒã§ã‚‹ãªã‚‰ã€‚
```sh
  0%|                                                                                                                            | 0/5000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/workspace/Isaac-GR00T/scripts/gr00t_finetune.py", line 315, in <module>
    main(config)
  File "/workspace/Isaac-GR00T/scripts/gr00t_finetune.py", line 287, in main
    experiment.train()
  File "/workspace/Isaac-GR00T/gr00t/experiment/runner.py", line 173, in train
    self.trainer.train(resume_from_checkpoint=self.resume_from_checkpoint)
  File "/workspace/Isaac-GR00T/gr00t/experiment/trainer.py", line 153, in train
    return super().train(resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)
  File "/venv/gr00t/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/venv/gr00t/lib/python3.10/site-packages/transformers/trainer.py", line 2514, in _inner_training_loop
    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
  File "/venv/gr00t/lib/python3.10/site-packages/transformers/trainer.py", line 5243, in get_batch_samples
    batch_samples.append(next(epoch_iterator))
  File "/venv/gr00t/lib/python3.10/site-packages/accelerate/data_loader.py", line 552, in __iter__
    current_batch = next(dataloader_iter)
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1465, in _next_data
    return self._process_data(data)
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/venv/gr00t/lib/python3.10/site-packages/torch/_utils.py", line 714, in reraise
    raise RuntimeError(msg) from None
RuntimeError: Caught MemoryError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/venv/gr00t/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 508, in __getitem__
    return self.transforms(self.get_step_data(trajectory_id, base_index))
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 542, in get_step_data
    data[key] = self.get_data_by_modality(trajectory_id, modality, key, base_index)
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 802, in get_data_by_modality
    return self.get_video(trajectory_id, key, base_index)
  File "/workspace/Isaac-GR00T/gr00t/data/dataset.py", line 672, in get_video
    return get_frames_by_timestamps(
  File "/workspace/Isaac-GR00T/gr00t/utils/video.py", line 112, in get_frames_by_timestamps
    for frame in reader:
  File "/venv/gr00t/lib/python3.10/site-packages/torchvision/io/video_reader.py", line 200, in __next__
    frame = next(self._c)
  File "av/container/input.pyx", line 208, in decode
  File "av/packet.pyx", line 80, in av.packet.Packet.decode
  File "av/video/stream.pyx", line 41, in av.video.stream.VideoStream.decode
  File "av/video/stream.pyx", line 50, in av.video.stream.VideoStream.decode
  File "av/codec/context.pyx", line 462, in av.codec.context.CodecContext.decode
  File "av/codec/context.pyx", line 238, in av.codec.context.CodecContext.open
  File "av/error.pyx", line 326, in av.error.err_check
av.error.MemoryError: [Errno 12] Cannot allocate memory
```

ã„ã£ãŸã‚“PyAVã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹
```sh
pip install -U av
```

## ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
```sh
# ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
cd so101-checkpoints/checkpoint-5000/

# å‰Šé™¤
# rm -rf scheduler.pt 
# rm -rf optimizer.pt

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
huggingface-cli upload \ 
      --repo-type model yuk6ra/so101-onetape-cleanup . \
      --commit-message="5000 step"
```

ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—çµ‚ãˆãŸã‚‰ã€å€Ÿã‚Šã¦ã„ãŸã‚µãƒ¼ãƒãƒ¼ã¯ã™ãã«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å‰Šé™¤ã—ã‚ˆã†ã€‚å¿˜ã‚Œãšã«æ³¨æ„ã€‚

# æ¨è«–ç·¨

æ¨è«–ã‚µãƒ¼ãƒãƒ¼ã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒãƒ¼ãƒ‰ã«åˆ¥ã‚Œã¾ã™ã€‚

## æ¨è«–ã‚µãƒ¼ãƒãƒ¼ã®ä»®æƒ³ç’°å¢ƒã®æ§‹ç¯‰

ãƒ­ãƒ¼ã‚«ãƒ«ã®å ´åˆã¨ã‚¯ãƒ©ã‚¦ãƒ‰ã®å ´åˆã«åˆ†ã‹ã‚Œã‚‹ã€‚

### ãƒ­ãƒ¼ã‚«ãƒ«ã®å ´åˆ
ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚‚åŒã˜ã‚ˆã†ã«ã€ç’°å¢ƒã‚’ä½œã‚‹ã€‚
æ¨è«–ã‚µãƒ¼ãƒãƒ¼ãŒåˆ¥PCã§ã‚ã‚Œã°ã€ã‚‚ã†ä¸€åº¦GR00T N1ã®ç’°å¢ƒã‚’ã¤ãã‚‹ã€‚

åŒæ§˜ã®ç’°å¢ƒã‚’ä½œã‚‹ã€‚

```sh
git clone https://github.com/NVIDIA/Isaac-GR00T
cd Isaac-GR00T
conda create -n gr00t python=3.10
conda activate gr00t
pip install --upgrade setuptools
pip install -e .[base]
pip install --no-build-isolation flash-attn==2.7.1.post4
```

å‚è€ƒæ–‡çŒ®ï¼šhttps://huggingface.co/docs/lerobot/installation

### ã‚¯ãƒ©ã‚¦ãƒ‰ã®å ´åˆ

ã‚¤ãƒ¡ãƒ¼ã‚¸ãªã©ã«ä¸‹è¨˜ã®ä»»æ„ã®ãƒãƒ¼ãƒˆã‚’ã‚ã‘ã¦ãã ã•ã„ã€‚
ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯5000ã«ãªã£ã¦ã„ã¾ã™ã€‚
```
-p 5555:5555
```

## ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

```sh
# ãƒ­ã‚°ã‚¤ãƒ³
huggingface-cli login


# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
huggingface-cli download \
     --repo-type model yuk6ra/so101-onetape-cleanup \
     --local-dir ./model/so101-onetape-cleanup
```

## æ¨è«–ã‚µãƒ¼ãƒãƒ¼ã®ç«‹ã¡ä¸Šã’
### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ
- 4070 Ti 12GB
- 128GB
- Ubuntu 22.04
- 

```sh
$ nvidia-smi
Sun Jul 13 19:45:37 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.153.02             Driver Version: 570.153.02     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4070 Ti     Off |   00000000:01:00.0  On |                  N/A |
|  0%   34C    P8              6W /  285W |     682MiB /  12282MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A            2453      G   /usr/lib/xorg/Xorg                      309MiB |
|    0   N/A  N/A            2608      G   /usr/bin/gnome-shell                     70MiB |
|    0   N/A  N/A            3211      G   /opt/brave.com/brave/brave                3MiB |
|    0   N/A  N/A            3254      G   ...c0b8c13d56e6779503f2cc987a424        119MiB |
|    0   N/A  N/A            5526      G   ...ess --variations-seed-version        125MiB |
+-----------------------------------------------------------------------------------------+
```


```sh
$ lsb_release -d
Description:	Ubuntu 22.04.5 LTS
```

ç«‹ã¡ä¸Šã’ã‚‹
```sh
python scripts/inference_service.py --model_path ./model/so101-onetape-cleanup --embodiment_tag new_embodiment --data_config so100_dualcam --server --port 5555
```

ä¸‹è¨˜ã®çŠ¶æ…‹ã«ãªã‚Œã°ç«‹ã¡ä¸ŠãŒã£ãŸã€‚
```
Server is ready and listening on tcp://0.0.0.0:5555
```

ãªãŠã€`so100_dualcam`ã§ã¾ãŸåŒã˜ãã€ãªãŠã™ã€‚`gr00t/experiment/data_config.py`ã‚’ç›´ã™ã€‚ç›´ã•ãªã„ã¨`ValueError: Video key wrist not found in dataset metadata. Available keys: dict_keys(['front', 'tip'])`ã¨ã§ã‚‹ã€‚

####ã€€ã‚¨ãƒ©ãƒ¼
```sh
pip install --no-build-isolation flash-attn==2.7.1.post4 

Collecting flash-attn==2.7.1.post4
  Using cached flash_attn-2.7.1.post4.tar.gz (2.7 MB)
  Preparing metadata (setup.py) ... error
  error: subprocess-exited-with-error
  
  Ã— python setup.py egg_info did not run successfully.
  â”‚ exit code: 1
  â•°â”€> [20 lines of output]
      fatal: not a git repository (or any of the parent directories): .git
      /tmp/pip-install-myxzi7su/flash-attn_3ea6f071d2e84485a9e98af6137eb7b7/setup.py:99: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.
        warnings.warn(
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 35, in <module>
        File "/tmp/pip-install-myxzi7su/flash-attn_3ea6f071d2e84485a9e98af6137eb7b7/setup.py", line 184, in <module>
          CUDAExtension(
        File "/home/yuk6ra/anaconda3/envs/gr00t/lib/python3.10/site-packages/torch/utils/cpp_extension.py", line 1078, in CUDAExtension
          library_dirs += library_paths(cuda=True)
        File "/home/yuk6ra/anaconda3/envs/gr00t/lib/python3.10/site-packages/torch/utils/cpp_extension.py", line 1209, in library_paths
          if (not os.path.exists(_join_cuda_home(lib_dir)) and
        File "/home/yuk6ra/anaconda3/envs/gr00t/lib/python3.10/site-packages/torch/utils/cpp_extension.py", line 2416, in _join_cuda_home
          raise OSError('CUDA_HOME environment variable is not set. '
      OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.
      
      
      torch.__version__  = 2.5.1+cu124
      
      
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

Ã— Encountered error while generating package metadata.
â•°â”€> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
```

ã“ã‚Œã‚’å…¥ã‚Œã‚‹
```
conda install -c nvidia cuda-toolkit=12.4
```

#### ã‚¨ãƒ©ãƒ¼
ã‚‚ã—`ModuleNotFoundError: No module named 'flash_attn'`ãŒå‡ºãŸã‚‰ã€ä»®æƒ³ç’°å¢ƒãŒ`gr00t`ã§ã¯ãªã`lerobot`ã‚„`base`ã®ç’°å¢ƒã«ãªã£ã¦ã„ãªã„ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚

## ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µãƒ¼ãƒãƒ¼ã®ç«‹ã¡ä¸Šã’

å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†ã®ã¨ãã«Lerobotã®ç’°å¢ƒã‚’ä½œã£ã¦ã„ã‚‹ã¨æ€ã„ã¾ã™ã€‚

LeRobotã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨äº’æ›æ€§ã‚’ä¿ã¤å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚lerobotã®ç’°å¢ƒã‚’ã¤ãã‚‹ã‚„ã‚‹ã€‚ã‚‚ã†ã™ã§ã«ã‚ã‚Œã°OKã§å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ãŸã¨ãã®ã‚‚ã®ã§OKã€‚

å¿µã®ç‚ºã€‚
```sh
git clone https://github.com/huggingface/lerobot.git
cd lerobot
conda create -y -n lerobot python=3.10
conda activate lerobot
conda install ffmpeg -c conda-forge
pip install -e .
pip install -e ".[feetech]"
```

Isaac-GR00Tã®ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•ã—ã¦ç’°å¢ƒã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã€‚


`Isaac-GR00T`ã¾ã§ç§»å‹•ã—ã¦ã€
```sh
# ç§»å‹•
cd ~/Documents/Isaac-GR00T/

# lerobotã‚’ç«‹ã¡ä¸Šã’ã‚‹
conda activate lerobot
```

ã•ã‚‰ã«è¿½åŠ ã§ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨gr00tã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‚
```sh
pip install matplotlib
```


`outputs/captured_images`ä»¥ä¸‹ã§ã‚«ãƒ¡ãƒ©ã®IDã‚’ãƒ¡ãƒ¢ã—ã¦ãŠãã€‚
`tip`ãŒ`2`ã€`front`ãŒ`0`ã§ã‚ã£ãŸã€‚
```sh
python -m lerobot.find_cameras opencv
```

`getting_started/examples/eval_lerobot.py`ã§ã€lerobotã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒã‚ã£ã¦ã„ãªã„ã®ã§`common`ã‚’æ¶ˆã™ã€‚

```python
from lerobot.cameras.opencv.configuration_opencv import ( # <---commonã‚’æ¶ˆã™
    OpenCVCameraConfig,
)
from lerobot.robots import ( # <---commonã‚’æ¶ˆã™
    Robot,
    RobotConfig,
    koch_follower,
    make_robot_from_config,
    so100_follower,
    so101_follower,
)
from lerobot.utils.utils import ( # <---commonã‚’æ¶ˆã™
    init_logging,
    log_say,
)

# NOTE:
# Sometimes we would like to abstract different env, or run this on a separate machine
# User can just move this single python class method gr00t/eval/service.py
# to their code or do the following line below
import os # <--- è¿½åŠ 
import sys # <--- è¿½åŠ 
sys.path.append(os.path.expanduser("./gr00t/eval/")) # <--- ãƒ‘ã‚¹ã®ä¿®æ­£
from service import ExternalRobotInferenceClient
```

```sh
python getting_started/examples/eval_lerobot.py \
         --robot.type=so101_follower \
         --robot.port=/dev/ttyACM1 \
         --robot.id=white \
         --robot.cameras="{
             tip: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30},
             front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}
         }" \
         --lang_instruction="Grab the tape and place it in the box."
```

### ã‚¯ãƒ©ã‚¦ãƒ‰å‘ã‘
ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‹ã‚‰æ¨è«–ã‚µãƒ¼ãƒãƒ¼ã«å‘ã‘ã¦ã€
```sh
python getting_started/examples/eval_lerobot.py \
       --robot.type=so101_follower \
       --robot.port=/dev/ttyACM0 \
       --robot.id=white \
       --robot.cameras="{
           tip: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30},
           front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}
       }" \
       --policy_host 194.14.47.19 \ # è¿½åŠ 
       --policy_port 22037 \ # è¿½åŠ 
       --lang_instruction="Grab tapes and place into pen holder."
```


# è©•ä¾¡ç·¨
è©•ä¾¡ã—ã¦ã¿ã‚‹ã€‚
## è©•ä¾¡ã™ã‚‹

ãƒ‡ãƒ¼ã‚¿ã‚’è½ã¨ã™ã€‚
```shell
huggingface-cli download \
       --repo-type dataset yuk6ra/so101-onetape-cleanup \
       --local-dir ./demo_data/so101-onetape-cleanup
```

ã“ã“ã‚’ã‚ˆã—ãªã«ä¿®æ­£ã™ã‚‹ã€‚
```shell
cp getting_started/examples/so100_dualcam__modality.json ./demo_data/so101-onetape-cleanup/meta/modality.json
```

é©å½“ã«`./demo_data/so101-onetape-cleanup/meta/modality.json`ã‚’ç›´ã™ã€‚

```json
 {
    ...
        "video": {
            "front": {
                "original_key": "observation.images.front"
            },
            "tip": {ã€€// `wrist`ã‹ã‚‰`tip`ã¸å¤‰æ›´
                "original_key": "observation.images.tip"  // `wrist`ã‹ã‚‰`tip`ã¸å¤‰æ›´
            }
        },
    ...
```

ãƒãƒªã‚·ãƒ¼ã‚’è©•ä¾¡ã™ã‚‹ã€‚

```shell
python scripts/eval_policy.py \
    --plot \
    --embodiment_tag new_embodiment \
    --model_path ./model/so101-onetape-cleanup/ \
    --data_config so100_dualcam \
    --dataset_path ./demo_data/so101-onetape-cleanup/ \
    --video_backend torchvision_av \
    --modality_keys single_arm gripper \
    --denoising_steps 4
```

çµæœã€
![](/images/c474627fe7775b/plot.png)

ãªãŠã€`so100_dualcam`ã‚’ç›´ã™ãŸã‚ã«ã€
`gr00t/experiment/data_config.py`ã®**225è¡Œç›®**ã«ã¯æ³¨æ„ã—ã¦æ›¸ãæ›ãˆã‚‹ã€‚

```python
class So100DualCamDataConfig(So100DataConfig):
- video_keys = ["video.front", "video.wrist"]
+ video_keys = ["video.front", "video.tip"]
```

### ã‚¨ãƒ©ãƒ¼ï¼š`ModuleNotFoundError: No module named 'tyro'`

ã‚‚ã—`ModuleNotFoundError: No module named 'flash_attn'`ãŒå‡ºãŸã‚‰ã€ä»®æƒ³ç’°å¢ƒãŒ`gr00t`ã§ã¯ãªã`lerobot`ã‚„`base`ã®ç’°å¢ƒã«ãªã£ã¦ã„ãªã„ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚


## å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™

```sh
huggingface-cli download \
       --repo-type dataset yuk6ra/so101-onetape-cleanup \
       --local-dir ./demo_data/so101-onetape-cleanup

cp getting_started/examples/so100_dualcam__modality.json ./demo_data/so101-onetape-cleanup/meta/modality.json
```


å¿…è¦ã§ã‚ã‚Œã°ç›´ã™ã€‚
```sh
vim ./demo_data/so101-onetape-cleanup/meta/modality.json
```

## ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™

ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã‚ã‚Œã°ã€‚
```sh
huggingface-cli download \
    --repo-type model  yuk6ra/so101-onetape-cleanup \
    --local-dir ./model/so101-onetape-cleanup
    # --revision step-5000
```

## è©•ä¾¡ã™ã‚‹

```sh
python scripts/eval_policy.py --plot \
       --embodiment_tag new_embodiment \
       --model_path ./model/so101-onetape-cleanup/ \
       --data_config so100_dualcam \
       --dataset_path ./demo_data/so101-onetape-cleanup/ \
       --video_backend torchvision_av \
       --modality_keys single_arm gripper \
       --denoising_steps 4
```

## æ¯”è¼ƒæ¤œè¨ã™ã‚‹

2000ã¨5000


# ã¾ã¨ã‚

ã‚ã‚ã‚
